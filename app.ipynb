{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --ClearMetadataPreprocessor.enabled=True --inplace \"text_to_image_generation_Diffusion_Models.ipynb\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e98sxDfWHV1",
        "outputId": "db15368e-488d-498a-eee0-6a650824cb39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nbconvert"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OHZmC52dHvl",
        "outputId": "44c8e6d6-800f-4f45-c632-2b4ca641d966"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers transformers accelerate safetensors --quiet"
      ],
      "metadata": {
        "id": "EBHDvZvpZkv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, StableDiffusionXLPipeline\n",
        "from transformers import CLIPTextModel, CLIPTokenizer\n",
        "from PIL import Image\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Check GPU availability\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Prompt for image generation\n",
        "prompt = \"A futuristic city at sunset with flying cars\"\n",
        "\n",
        "# Function to display images\n",
        "def display_images(images, titles):\n",
        "    fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n",
        "    for i, (img, title) in enumerate(zip(images, titles)):\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(title)\n",
        "        axes[i].axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Initialize results\n",
        "images = []\n",
        "titles = []\n",
        "times = []\n"
      ],
      "metadata": {
        "id": "J5elqIOhZlBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Stable Diffusion v1.5\n",
        "print(\"Generating with Stable Diffusion v1.5...\")\n",
        "start_time = time.time()\n",
        "pipe_v15 = StableDiffusionPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True\n",
        ").to(device)\n",
        "image_v15 = pipe_v15(\n",
        "    prompt=prompt,\n",
        "    num_inference_steps=50,\n",
        "    height=512,\n",
        "    width=512\n",
        ").images[0]\n",
        "time_v15 = time.time() - start_time\n",
        "images.append(image_v15)\n",
        "titles.append(\"Stable Diffusion v1.5\")\n",
        "times.append(time_v15)\n",
        "image_v15.save(\"stable_diffusion_v15.png\")\n",
        "del pipe_v15\n",
        "torch.cuda.empty_cache()\n",
        "\n"
      ],
      "metadata": {
        "id": "6qsCKVyqZrJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Stable Diffusion XL (SDXL)\n",
        "print(\"Generating with Stable Diffusion XL...\")\n",
        "start_time = time.time()\n",
        "pipe_sdxl = StableDiffusionXLPipeline.from_pretrained(\n",
        "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True\n",
        ").to(device)\n",
        "# Load CLIP tokenizer and text encoder for text embeddings\n",
        "tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\")\n",
        "text_encoder = CLIPTextModel.from_pretrained(\n",
        "    \"openai/clip-vit-large-patch14\",\n",
        "    torch_dtype=torch.float16\n",
        ").to(device)\n",
        "# Tokenize prompt\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
        "# Generate text embeddings\n",
        "with torch.no_grad():\n",
        "    text_embeds = text_encoder(**inputs).pooler_output\n",
        "# Placeholder time_ids (SDXL-specific)\n",
        "time_ids = torch.zeros((1, 6), dtype=torch.float16).to(device)\n",
        "# Generate image\n",
        "image_sdxl = pipe_sdxl(\n",
        "    prompt=prompt,\n",
        "    num_inference_steps=50,\n",
        "    height=1024,\n",
        "    width=1024,\n",
        "    added_cond_kwargs={\"text_embeds\": text_embeds, \"time_ids\": time_ids}\n",
        ").images[0]\n",
        "time_sdxl = time.time() - start_time\n",
        "images.append(image_sdxl)\n",
        "titles.append(\"Stable Diffusion XL\")\n",
        "times.append(time_sdxl)\n",
        "image_sdxl.save(\"stable_diffusion_xl.png\")\n",
        "del pipe_sdxl, tokenizer, text_encoder\n",
        "torch.cuda.empty_cache()\n",
        "\n"
      ],
      "metadata": {
        "id": "Rri89wywZut3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. DALL-E Mini (using min-dalle)\n",
        "print(\"Generating with DALL-E Mini...\")\n",
        "start_time = time.time()\n",
        "try:\n",
        "    from min_dalle import MinDalle\n",
        "except ImportError:\n",
        "    !pip install min-dalle\n",
        "    from min_dalle import MinDalle\n",
        "# Initialize MinDalle model\n",
        "model = MinDalle(\n",
        "    models_root='./pretrained',\n",
        "    dtype=torch.float16,\n",
        "    device=device,\n",
        "    is_mega=False,  # Use the smaller model for compatibility\n",
        "    is_reusable=True\n",
        ")\n",
        "# Generate image\n",
        "image_dalle = model.generate_image(\n",
        "    text=prompt,\n",
        "    seed=42,  # Fixed seed for reproducibility\n",
        "    grid_size=1,  # Generate one image\n",
        "    is_seamless=False,\n",
        "    temperature=1,\n",
        "    top_k=128\n",
        ")\n",
        "time_dalle = time.time() - start_time\n",
        "images.append(image_dalle)\n",
        "titles.append(\"DALL-E Mini\")\n",
        "times.append(time_dalle)\n",
        "image_dalle.save(\"dalle_mini.png\")\n",
        "del model\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Display all images together\n",
        "display_images(images, titles)\n"
      ],
      "metadata": {
        "id": "d5ehHP4jZ3hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Comparative Analysis\n",
        "print(\"\\nComparative Analysis:\")\n",
        "print(f\"{'Model':<25} {'Time (s)':<10} {'Resolution':<15} {'VRAM (GB)':<10}\")\n",
        "print(\"-\" * 60)\n",
        "print(f\"{'Stable Diffusion v1.5':<25} {time_v15:<10.2f} {'512x512':<15} {'~6-8':<10}\")\n",
        "print(f\"{'Stable Diffusion XL':<25} {time_sdxl:<10.2f} {'1024x1024':<15} {'~10-12':<10}\")\n",
        "print(f\"{'DALL-E Mini':<25} {time_dalle:<10.2f} {'256x256':<15} {'~4-6':<10}\")\n"
      ],
      "metadata": {
        "id": "ARaAsQuUZ6sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Subjective Evaluation\n",
        "print(\"\\nSubjective Evaluation:\")\n",
        "print(\"- Stable Diffusion v1.5: Good quality, moderate detail, decent prompt adherence.\")\n",
        "print(\"- Stable Diffusion XL: High-quality, sharp details, excellent prompt adherence.\")\n",
        "print(\"- DALL-E Mini: Lower resolution, less detail, moderate prompt adherence.\")"
      ],
      "metadata": {
        "id": "1pi5TGUOaDIm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}